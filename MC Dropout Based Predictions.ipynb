{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21e1871",
   "metadata": {},
   "source": [
    "# MC DropOut\n",
    "\n",
    "Under regular classification MC Dropout works like this:\n",
    "\n",
    "You take a **trained** model $f(\\ , \\theta^*)$ , and input some data to it (do inference).\n",
    "But you add some noise (in the form of dropout) and do repeated inference.\n",
    "\n",
    "#### Dropout\n",
    "\n",
    "Dropout makes some parameters of the model zero so some neurons don't work. This is done randomly.\n",
    "So let the model be defined by a specific set of $M$ parameters $\\theta^t \\in \\mathcal{R}^M$.\n",
    "\n",
    "Implementing dropout can be defined as randomly sampling a mask from a binary space of the same dimensions: $m \\in \\{ 0,1 \\}^M$.\n",
    "\n",
    "We can get a new set of parameters of the model by doing a hadamard product between the parameters and the mask by\n",
    "$\\theta_d^t = \\theta^t \\odot m$\n",
    "\n",
    "#### Implications\n",
    "\n",
    "In doing so, we effectively make a new model.\n",
    "If we sample multiple masks, we get different models. \n",
    "\n",
    "#### MC Dropout\n",
    "\n",
    "Use different models (by different dropouts) to predictions on the same input. Use them to compute confidence intervals\n",
    "\n",
    "\n",
    "## MCD on Link Prediction\n",
    "\n",
    "We're can't do the _exact_ same thing in our task so we'll make some adjustments to it.\n",
    "\n",
    "# TODO: write out the rest\n",
    "\n",
    "Get a matrix of nument x 100\n",
    "A .8 softmax score of 95% means a particular entity gets a softmax of 0.8 95% of the times or more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb22796",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "- Load a model\n",
    "- Get a way to get all training valid and test triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c67819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.0.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/hchoi/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "from run import Runner\n",
    "from mytorch.utils.goodies import FancyDict\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm, trange\n",
    "import torch\n",
    "from typing import Union, Optional, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6558978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-26 13:45:09,623 - [INFO] - {}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "args = {'name' : 'testrun',\n",
    "'dataset' : 'RLF/lf-cp',\n",
    "'model' : 'compgcn',\n",
    "'score_func' : 'conve',\n",
    "'opn' : 'corr',                 \n",
    "'use_wandb' : False, \n",
    "'batch_size' : 128,       \n",
    "'gamma' : 40.0,\t\t\t\n",
    "'gpu' : '-1',\t\t\t\n",
    "'max_epochs' : 1,  \t\n",
    "'l2' : 0.0,\t\t\t\n",
    "'lr' : 0.001,\t\t\t\n",
    "'lbl_smooth' : 0.1,\t\n",
    "'num_workers' : 10,                     \n",
    "'seed' : 41504,     \t\n",
    "'restore' : False,            \n",
    "'bias' : False   ,         \n",
    "'num_bases' : -1, \t\n",
    "'init_dim' : 100,\t\n",
    "'gcn_dim' : 200 ,\t\n",
    "'embed_dim' : None, \t\n",
    "'gcn_layer' : 1 \t,\n",
    "'dropout' : 0.05\t,\n",
    "'hid_drop' : 0.15\t,\n",
    "'hid_drop2' : 0.15\t,\n",
    "'feat_drop' : 0.15\t,\n",
    "'k_w' : 10 \t,\n",
    "'k_h' : 20 \t,\n",
    "'num_filt' : 200, \t\n",
    "'ker_sz' : 7 \t,\n",
    "'log_dir' : './log/',               \n",
    "'config_dir' : './config/',\n",
    "'trim': False,\n",
    "'trim_ratio': 0.00005,\n",
    "'use_fasttext': False\n",
    "}\n",
    "args = FancyDict(args)\n",
    "\n",
    "model = Runner(args)\n",
    "# # Now load the saved model\n",
    "model.load_model('./checkpoints/rlf-lf-cp_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d796a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3889e08f90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa17f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub</th>\n",
       "      <th>rel</th>\n",
       "      <th>obj</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8220</td>\n",
       "      <td>0</td>\n",
       "      <td>17574</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15043</td>\n",
       "      <td>0</td>\n",
       "      <td>20547</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3475</td>\n",
       "      <td>0</td>\n",
       "      <td>19623</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8854</td>\n",
       "      <td>59</td>\n",
       "      <td>1729</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26410</td>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>6511</td>\n",
       "      <td>9</td>\n",
       "      <td>21561</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6696</th>\n",
       "      <td>7902</td>\n",
       "      <td>10</td>\n",
       "      <td>4923</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6697</th>\n",
       "      <td>3959</td>\n",
       "      <td>10</td>\n",
       "      <td>8307</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>6227</td>\n",
       "      <td>0</td>\n",
       "      <td>11702</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>861</td>\n",
       "      <td>0</td>\n",
       "      <td>24245</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6700 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sub  rel    obj split\n",
       "0      8220    0  17574  test\n",
       "1     15043    0  20547  test\n",
       "2      3475    0  19623  test\n",
       "3      8854   59   1729  test\n",
       "4     26410    0    780  test\n",
       "...     ...  ...    ...   ...\n",
       "6695   6511    9  21561  test\n",
       "6696   7902   10   4923  test\n",
       "6697   3959   10   8307  test\n",
       "6698   6227    0  11702  test\n",
       "6699    861    0  24245  test\n",
       "\n",
       "[6700 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr = pd.DataFrame(model.data['train'], columns=['sub', 'rel', 'obj'])\n",
    "df_tr['split'] = 'train'\n",
    "df_tr\n",
    "\n",
    "df_vl = pd.DataFrame(model.data['valid'], columns=['sub', 'rel', 'obj'])\n",
    "df_vl['split'] = 'valid'\n",
    "df_vl\n",
    "\n",
    "df_ts = pd.DataFrame(model.data['test'], columns=['sub', 'rel', 'obj'])\n",
    "df_ts['split'] = 'test'\n",
    "\n",
    "dfs = {'train': df_tr, 'valid': df_vl, 'test': df_ts}\n",
    "\n",
    "df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "118c3610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total       utilisé      libre     partagé tamp/cache   disponible\r\n",
      "Mem:            62Gi       5,7Gi        34Gi       1,4Gi        22Gi        54Gi\r\n",
      "Partition d'échange:      1,9Gi          0B       1,9Gi\r\n"
     ]
    }
   ],
   "source": [
    "! free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb9a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold(\n",
    "    model: Runner, \n",
    "    dfs: Dict[str, pd.DataFrame], \n",
    "    sub: Union[str, int], \n",
    "    rel: Optional[Union[str, int]] = None,\n",
    "    return_str: bool = False,\n",
    "    return_merged: bool = False\n",
    "):\n",
    "    \n",
    "    # Encode the sub and rel \n",
    "    i_sub = sub if type(sub) is int else model.ent2id[sub]\n",
    "    i_rel = None\n",
    "    \n",
    "    if rel is not None:\n",
    "        i_rel = rel if type(rel) is int else model.rel2id[rel]\n",
    "        \n",
    "    # Unpack dfs\n",
    "    df_tr, df_vl, df_ts = dfs['train'], dfs['valid'], dfs['test']    \n",
    "        \n",
    "    # Get train matches\n",
    "    temp = df_tr[df_tr['sub'] == i_sub]\n",
    "    if rel is not None:\n",
    "        temp = temp[temp['rel'] == i_rel]\n",
    "    tr_o = temp.obj.values.tolist()\n",
    "    tr_r = temp.rel.values.tolist()\n",
    "    \n",
    "    # Get valid matches\n",
    "    temp = df_vl[df_vl['sub'] == i_sub]\n",
    "    if rel is not None:\n",
    "        temp = temp[temp['rel'] == i_rel]\n",
    "    vl_o = temp.obj.values.tolist()\n",
    "    vl_r = temp.rel.values.tolist()\n",
    "    \n",
    "    # Get test matches\n",
    "    temp = df_ts[df_ts['sub'] == i_sub]\n",
    "    if rel is not None:\n",
    "        temp = temp[temp['rel'] == i_rel]\n",
    "    ts_o = temp.obj.values.tolist()\n",
    "    ts_r = temp.rel.values.tolist()\n",
    "    \n",
    "    if return_str:\n",
    "        # we encode everything and send back\n",
    "        tr_o = [model.id2ent[x] for x in tr_o]\n",
    "        vl_o = [model.id2ent[x] for x in vl_o]\n",
    "        ts_o = [model.id2ent[x] for x in ts_o]\n",
    "        tr_r = [model.id2rel[x] for x in tr_r]\n",
    "        vl_r = [model.id2rel[x] for x in vl_r]\n",
    "        ts_r = [model.id2rel[x] for x in ts_r]\n",
    "        \n",
    "    if return_merged:\n",
    "        return tr_o + vl_o + ts_o, tr_r + vl_r + ts_r\n",
    "\n",
    "    return tr_o, tr_r, vl_o, vl_r, ts_o, ts_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a96a4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_dropout(model):\n",
    "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__.startswith('Dropout'):\n",
    "            m.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe55c1",
   "metadata": {},
   "source": [
    "# Actual Stuff\n",
    "\n",
    "- For a given sub, rel\n",
    "- Get 100 model predictions using dropout\n",
    "- Make a ne x 100 matrix\n",
    "- Mask out columns corresponding to triples already existing in the dataset\n",
    "- Do a softmax for each row\n",
    "- For a given confidence interval and for a given threshold, get the candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1ebe87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 'table ii.1a'\n",
    "sub = 'abus'\n",
    "rel = 'anti'\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55e382af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 27068])\n"
     ]
    }
   ],
   "source": [
    "# Get predictions using different dropouts\n",
    "\n",
    "# Let's get their IDs\n",
    "id_sub, id_rel = model.ent2id[sub], model.rel2id[rel]\n",
    "# Convert them to torch tensors of shape (n,) (repeat the same sub, rel 100 times)\n",
    "t_sub = torch.tensor(id_sub).repeat(n)\n",
    "t_rel = torch.tensor(id_rel).repeat(n)\n",
    "\n",
    "# Get predictions based on that\n",
    "with torch.no_grad():\n",
    "    model.model.eval()   # enable dropouts\n",
    "    enable_dropout(model.model)\n",
    "    pred = model.model.forward(t_sub, t_rel)\n",
    "\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e756ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f95b9aa876421c8555caa1771dc9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 27068])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alt: instead of that, really get predictions by running a for loop n times\n",
    "t_sub = torch.tensor(id_sub).repeat(2)\n",
    "t_rel = torch.tensor(id_rel).repeat(2)\n",
    "\n",
    "pred = torch.zeros(n, model.p.num_ent, dtype=torch.float32)\n",
    "model.model.eval()\n",
    "enable_dropout(model.model)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in trange(n):\n",
    "        pred[i] = model.model.forward(t_sub, t_rel)[0]\n",
    "        \n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "692c142f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27068]), [], tensor(0))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mask to put on the preds\n",
    "objs, rels = get_gold(model, dfs, sub, rel, return_merged=True)\n",
    "# mask = torch.tensor(objs)\n",
    "mask = torch.zeros(model.p.num_ent, dtype=torch.bool)\n",
    "mask[objs] = 1\n",
    "mask.shape, objs, mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9582aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the mask on the pred\n",
    "pred_masked = pred.clone()\n",
    "pred_masked[:, mask] = -10**10\n",
    "\n",
    "# Do softmax (per row) over the pred\n",
    "pred_masked_soft = torch.softmax(pred_masked, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "838a771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now set a confidence and softmax score threshold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cecf545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k(preds, k=10):\n",
    "    # Get the top k candidates for each prediction and make a mask like that (boolean)\n",
    "    top_k = preds.argsort(dim=1, descending=True)[:,:k]\n",
    "    res = torch.zeros_like(preds, dtype=torch.bool)\n",
    "    for i, candidates in enumerate(top_k):\n",
    "        res[i, candidates] = True\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "701cb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_threshold(preds, threshold = 0.1):\n",
    "    return preds > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfc1b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(raw, selected, conf_threshold=0.5):\n",
    "    # Selected is a boolean mat of (num_ent, num_samples)\n",
    "    selected = selected.float()\n",
    "    per_entity_freq = selected.mean(dim=0)\n",
    "    avg = raw.mean(dim=0)\n",
    "    \n",
    "    # print top ten candidates\n",
    "    scores, indices = per_entity_freq.sort(descending=True)[:10]\n",
    "    print(\"Top scoring candidates by this method: \\n\\n(conf): (agg. score): node\")\n",
    "    for i in range(10):\n",
    "        print(f\"{scores[i]:.4f}: {avg[indices[i]].item():.10f}: {model.id2ent[indices[i].item()]}\")\n",
    "        \n",
    "    return per_entity_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e52d66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(pred_masked):\n",
    "    per_entity_freq = pred_masked.mean(dim=0)\n",
    "    # print top ten candidates\n",
    "    scores, indices = per_entity_freq.sort(descending=True)[:10]\n",
    "    print(\"Top scoring candidates by this method: \\n\\n(conf): node\")\n",
    "    for i in range(10):\n",
    "        print(f\"{scores[i]:.10f}: {model.id2ent[indices[i].item()]}\")\n",
    "        \n",
    "    return per_entity_freq"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5a0902d",
   "metadata": {},
   "source": [
    "output = pred[0]\n",
    "\n",
    "predicted_nodes = torch.argsort(output, descending=True)[:10]\n",
    "predicted_scores = output[predicted_nodes]\n",
    "predicted_node_names = [model.id2ent[nodeid.item()] for nodeid in predicted_nodes]\n",
    "\n",
    "predicted_node_names, predicted_scores"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98d0302e",
   "metadata": {},
   "source": [
    "model.model.train()\n",
    "pred = model.model.forward(t_sub, t_rel)\n",
    "output = pred[0]\n",
    "\n",
    "predicted_nodes = torch.argsort(output, descending=True)[:10]\n",
    "predicted_scores = output[predicted_nodes]\n",
    "predicted_node_names = [model.id2ent[nodeid.item()] for nodeid in predicted_nodes]\n",
    "\n",
    "predicted_node_names, predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1610ad0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top scoring candidates by this method: \n",
      "\n",
      "(conf): (agg. score): node\n",
      "1.0000: 0.0000432348: abuser i\n",
      "0.1700: 0.0000369879: exploiter ii\n",
      "0.1600: 0.0000369953: écologue n, fém\n",
      "0.1500: 0.0000369815: honnêtement i.a\n",
      "0.1200: 0.0000369843: retentir ii\n",
      "0.1200: 0.0000369829: mollesse ii\n",
      "0.1200: 0.0000369726: froid adj ii\n",
      "0.1000: 0.0000369750: urgent\n",
      "0.1000: 0.0000369745: orphelin n i.a\n",
      "0.0900: 0.0000369738: potentiel adj\n"
     ]
    }
   ],
   "source": [
    "op = aggregate(pred_masked_soft, top_k(pred_masked_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4bc19c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top scoring candidates by this method: \n",
      "\n",
      "(conf): node\n",
      "0.0000432348: abuser i\n",
      "0.0000369953: écologue n, fém\n",
      "0.0000369879: exploiter ii\n",
      "0.0000369843: retentir ii\n",
      "0.0000369829: mollesse ii\n",
      "0.0000369815: honnêtement i.a\n",
      "0.0000369773: ter\n",
      "0.0000369750: urgent\n",
      "0.0000369745: orphelin n i.a\n",
      "0.0000369738: potentiel adj\n"
     ]
    }
   ],
   "source": [
    "op = avg(pred_masked_soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b68a16",
   "metadata": {},
   "source": [
    "# Rough, ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d34f05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4201,    10,  1678],\n",
       "         [ 5608,     6, 19065]]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batch = next(train_iter)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91323ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4201, 5608]),\n",
       " tensor([10,  6]),\n",
       " tensor([ 1678, 19065]),\n",
       " tensor([[ 1678, 17701, 17713,  ...,  8848,  8847,  8846],\n",
       "         [19065, 17701, 17713,  ...,  8848,  8847,  8846]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in batch]\n",
    "sub, rel, obj, label    = model.read_batch(batch, split)\n",
    "sub, rel, obj, label.argsort(dim=1, descending=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf2c794d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 26558])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.model.forward(sub, rel)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe8c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f05c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, split='valid', mode='tail_batch', n=100):\n",
    "    \"\"\"\n",
    "        Function to run model evaluation for a given mode\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        split: (string) \tIf split == 'valid' then evaluate on the validation set, else the test set\n",
    "        mode: (string):\t\tCan be 'head_batch' or 'tail_batch'\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        resutls:\t\t\tThe evaluation results containing the following:\n",
    "            results['mr']:         \tAverage of ranks_left and ranks_right\n",
    "            results['mrr']:         Mean Reciprocal Rank\n",
    "            results['hits@k']:      Probability of getting the correct prediction in top-k ranks based on predicted score\n",
    "\n",
    "    \"\"\"\n",
    "    model.model.train(True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        results = {}\n",
    "        train_iter = iter(model.data_iter['{}_{}'.format(split, mode.split('_')[0])])\n",
    "\n",
    "        for step, batch in enumerate(train_iter):\n",
    "            sub, rel, obj, label    = model.read_batch(batch, split)\n",
    "            pred            = model.model.forward(sub, rel)\n",
    "            b_range         = torch.arange(pred.size()[0], device=model.device)\n",
    "            target_pred     = pred[b_range, obj]\n",
    "            pred            = torch.where(label.byte(), -torch.ones_like(pred) * 10000000, pred)\n",
    "            pred[b_range, obj]  = target_pred\n",
    "            ranks           = 1 + torch.argsort(torch.argsort(pred, dim=1, descending=True), dim=1, descending=False)[b_range, obj]\n",
    "\n",
    "            ranks           = ranks.float()\n",
    "            results['count']    = torch.numel(ranks)        + results.get('count', 0.0)\n",
    "            results['mr']       = torch.sum(ranks).item()   + results.get('mr',    0.0)\n",
    "            results['mrr']      = torch.sum(1.0/ranks).item()   + results.get('mrr',   0.0)\n",
    "            for k in range(10):\n",
    "                results['hits@{}'.format(k+1)] = torch.numel(ranks[ranks <= (k+1)]) + results.get('hits@{}'.format(k+1), 0.0)\n",
    "\n",
    "\n",
    "    if report_all:\n",
    "        return results, all_ranks\n",
    "\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
